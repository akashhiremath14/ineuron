{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "json.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPs7aV4uu/6crdrcaWvYQYD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashhiremath14/ineuron/blob/master/json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CMPAJc45Euf",
        "outputId": "06b598c2-6331-43a4-9ff3-38de0b5df27a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_json('/content/drive/MyDrive/messages.json')\n"
      ],
      "metadata": {
        "id": "OX0Sh2IH8G1F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiwuSmrBvzy3",
        "outputId": "02e1ead2-f649-47f1-8f8c-526dad056b16"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iLTkkldhr43v"
      },
      "outputs": [],
      "source": [
        "temp = \"\"\n",
        "count =0\n",
        "eachmessagelist = []\n",
        "\n",
        "eachconvjson = {}\n",
        "\n",
        "for i in df['conversations'][0:16000]:\n",
        "  kc =0\n",
        "  eachmessagejson = {}\n",
        "  for k in i['MessageList']:\n",
        "    if(k['displayName'] is not None):\n",
        "      temp ={'type_' : 'Student','content' :k['content']}\n",
        "    elif(k['displayName'] is None):\n",
        "      temp ={'type_' :'Customer Care', 'content' : k['content']}\n",
        "    eachmessagejson[kc] = temp\n",
        "    kc = kc +1\n",
        "  eachconvjson[count] = eachmessagejson\n",
        "  count = count + 1 \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['conversations'][0]"
      ],
      "metadata": {
        "id": "hKxU991228SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "jo = json.dumps(eachconvjson,indent = 4)\n",
        "print()\n",
        "with open(\"sample.json\",'w') as of:\n",
        "  of.write(jo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y19XIBW22K4X",
        "outputId": "cbf8cd31-209c-4b42-9ef4-aefda0e00d03"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eachconvjson[0]"
      ],
      "metadata": {
        "id": "_jWgWZ3m5iX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_special_character(string): \n",
        "  \n",
        "    # Declaring variable for special characters \n",
        "    special_char= 0\n",
        "   \n",
        "    for i in range(0, len(string)):  \n",
        "    # len(string) function to count the \n",
        "    # number of characters in given string.\n",
        "      \n",
        "        ch = string[i]\n",
        "  \n",
        "        #.isalpha() function checks whether character \n",
        "        #is alphabet or not.\n",
        "        if (string[i].isalpha()):  \n",
        "            continue\n",
        "        \n",
        "        #.isdigit() function checks whether character \n",
        "        #is a number or not.\n",
        "        elif (string[i].isdigit()):\n",
        "            continue\n",
        "            \n",
        "        else: \n",
        "            special_char += 1\n",
        "            \n",
        "            \n",
        "    if special_char >= 4:    \n",
        "        return 1  \n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "Pd1nDKkEaiDX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count =0\n",
        "# f = open(\"demo.csv\", \"a\")\n",
        "# for i in df['conversations'][0:300]:\n",
        "#   f.write(f'{count}|.|.|')\n",
        "#   for k in i['MessageList']:\n",
        "#     if(k['displayName'] is not None):\n",
        "#       f.write(k['content'])\n",
        "#   count = count +1\n",
        "# f.close()\n",
        "      "
      ],
      "metadata": {
        "id": "slxR7M0Loj1U"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying to create a dataframe to akash dataset"
      ],
      "metadata": {
        "id": "PKdPF0HmKTob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count =0\n",
        "stri = \"\"\n",
        "data = []\n",
        "listn = []\n",
        "\n",
        "for i in df['conversations'][0:16000]:\n",
        "  listn= []\n",
        "  stri = \"\" \n",
        "  for k in i['MessageList']:\n",
        "    if(k['displayName'] is not None and k['messagetype']== 'RichText'):\n",
        "        stri = stri + \" \" + k['content']\n",
        "  listn.append(count)\n",
        "  listn.append(stri)\n",
        "  data.append(listn)\n",
        "  count = count +1\n"
      ],
      "metadata": {
        "id": "GWhvdia7KXeV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.DataFrame(data, columns=['Count', 'Content'])"
      ],
      "metadata": {
        "id": "enBos7pwMs8O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gRBgDDTANVFK",
        "outputId": "25b73851-f06c-4490-c3ca-84d08024318f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Count                                            Content\n",
              "15995  15995   The details about the entire package; course ...\n",
              "15996  15996   how can we do it suppose we want to maintain ...\n",
              "15997  15997   Thank you so much for your assistance  but I ...\n",
              "15998  15998   I need python which started from yesterday Th...\n",
              "15999  15999                                                   "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-295ab59c-6ce1-4247-a81d-7c48a84570c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15995</th>\n",
              "      <td>15995</td>\n",
              "      <td>The details about the entire package; course ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15996</th>\n",
              "      <td>15996</td>\n",
              "      <td>how can we do it suppose we want to maintain ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>15997</td>\n",
              "      <td>Thank you so much for your assistance  but I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15998</th>\n",
              "      <td>15998</td>\n",
              "      <td>I need python which started from yesterday Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15999</th>\n",
              "      <td>15999</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-295ab59c-6ce1-4247-a81d-7c48a84570c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-295ab59c-6ce1-4247-a81d-7c48a84570c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-295ab59c-6ce1-4247-a81d-7c48a84570c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/LIAAD/yake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nN1d_uSJJWy",
        "outputId": "af232249-833a-44e4-fa8a-a0ed66dce0ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/LIAAD/yake\n",
            "  Cloning https://github.com/LIAAD/yake to /tmp/pip-req-build-efcsr_44\n",
            "  Running command git clone -q https://github.com/LIAAD/yake /tmp/pip-req-build-efcsr_44\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (0.8.9)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (1.21.6)\n",
            "Collecting segtok\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (2.6.3)\n",
            "Collecting jellyfish\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 18.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake==0.4.8) (2022.6.2)\n",
            "Building wheels for collected packages: yake, jellyfish\n",
            "  Building wheel for yake (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yake: filename=yake-0.4.8-py2.py3-none-any.whl size=62602 sha256=3e632b82a5f6933a2109f67e91a8ad1a5d8bf2fb79e00b3e054995725926e793\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dl63cuf8/wheels/52/79/f4/dae9309f60266aa3767a4381405002b6f2955fbcf038d804da\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73977 sha256=cf07e9d2f04a286932fac5a9ac11b43fc452d957d6c9ce6262b79cdcec33f1c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built yake jellyfish\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "Successfully installed jellyfish-0.9.0 segtok-1.5.11 yake-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "##Creating a list of custom stopwords\n",
        "new_words = [\"fig\",\"figure\",\"image\",\"sample\",\"using\", \n",
        "             \"show\", \"result\", \"large\", \n",
        "             \"also\", \"one\", \"two\", \"three\", \n",
        "             \"four\", \"five\", \"seven\",\"eight\",\"nine\",'URIObject type','URIObject','URIObject uri'\n",
        "             'uri','http','api','url_thumbnail','sir']\n",
        "stop_words = list(stop_words.union(new_words))\n",
        "\n",
        "def pre_process(text):\n",
        "    \n",
        "    # lowercase\n",
        "    text=text.lower()\n",
        "    \n",
        "    #remove tags\n",
        "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
        "    \n",
        "    # remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    \n",
        "    ##Convert to list from string\n",
        "    text = text.split()\n",
        "    \n",
        "    # remove stopwords\n",
        "    text = [word for word in text if word not in stop_words]\n",
        "\n",
        "    # remove words less than three letters\n",
        "    text = [word for word in text if len(word) >= 3]\n",
        "\n",
        "    # lemmatize\n",
        "    lmtzr = WordNetLemmatizer()\n",
        "    text = [lmtzr.lemmatize(word) for word in text]\n",
        "    \n",
        "    return ' '.join(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EsgS_IVOeHS",
        "outputId": "9f6d40ce-e83a-41e2-8fca-456465d0f752"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n2df = new_df['Content'].apply(lambda x : pre_process(x))"
      ],
      "metadata": {
        "id": "G36aVws8TEMp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n2df[9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "A2gPFIPxV1-L",
        "outputId": "daeaa5a2-5f7f-42ab-cf75-36a03c368c6a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'assessment test course module check apos stand preparation provide interview question python mail content okkk assign mentor interview preparation resume preparation separate python project correct machine learning project python project python project hii completed python module prepare resume hello hello seen an oprn link check assignment href http github com ankur ineuron full stack data science assignment blob main assignment_ ipynb ineuron full stack data science assignment assignment_ ipynb main ankur ineuron full stack data science assignment github com issue resolved shared href http drive google com file lswgk sli ugbnn suujt snx view usp sharing http drive google com file lswgk sli ugbnn suujt snx view usp sharing upload file google drive opened provide step send issue please check wait original file contains an issue an showing see answer property open assignment waiting reply an showing properly showing correct please check assignment href http github com ankur ineuron full stack data science assignment blob main assignment_ ipynb http github com ankur ineuron full stack data science assignment blob main assignment_ ipynb an showing properly upload file github account file uploaded properly save assignment ipynb format local system change inside file connect min please assist issue submit assignment github hello connect please give demo submit assignment hello type wave'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yake\n",
        "\n",
        "\n",
        "def get_keywords_yake(idx, docs):\n",
        "    y = yake.KeywordExtractor(lan='en',          # language\n",
        "                             n = 2,              # n-gram size\n",
        "                             dedupLim = 0.95,     # deduplicationthresold\n",
        "                             dedupFunc = 'seqm', #  deduplication algorithm\n",
        "                             windowsSize = 1,\n",
        "                             top = 10,           # number of keys\n",
        "                             features=None)           \n",
        "    text = docs\n",
        "    keywords = y.extract_keywords(text)\n",
        "    return keywords\n",
        "\n",
        "def print_results(idx,keywords, df):\n",
        "    # now print the results\n",
        "    print(\"\\n===Keywords===\")\n",
        "    for k in keywords:\n",
        "        print(k)\n",
        "\n",
        "idx=9\n",
        "keywords = get_keywords_yake(idx, n2df[idx])\n",
        "print(n2df[idx])\n",
        "print_results(idx, keywords, n2df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEUlMe7UOelH",
        "outputId": "294debfa-5f09-409a-fd83-0ebcfdbc0e82"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assessment test course module check apos stand preparation provide interview question python mail content okkk assign mentor interview preparation resume preparation separate python project correct machine learning project python project python project hii completed python module prepare resume hello hello seen an oprn link check assignment href http github com ankur ineuron full stack data science assignment blob main assignment_ ipynb ineuron full stack data science assignment assignment_ ipynb main ankur ineuron full stack data science assignment github com issue resolved shared href http drive google com file lswgk sli ugbnn suujt snx view usp sharing http drive google com file lswgk sli ugbnn suujt snx view usp sharing upload file google drive opened provide step send issue please check wait original file contains an issue an showing see answer property open assignment waiting reply an showing properly showing correct please check assignment href http github com ankur ineuron full stack data science assignment blob main assignment_ ipynb http github com ankur ineuron full stack data science assignment blob main assignment_ ipynb an showing properly upload file github account file uploaded properly save assignment ipynb format local system change inside file connect min please assist issue submit assignment github hello connect please give demo submit assignment hello type wave\n",
            "\n",
            "===Keywords===\n",
            "('full stack', 0.0005609510058584673)\n",
            "('stack data', 0.0005609510058584673)\n",
            "('data science', 0.0005609510058584673)\n",
            "('ineuron full', 0.0006250837732895789)\n",
            "('science assignment', 0.0009008093234061258)\n",
            "('ankur ineuron', 0.0009691518124312076)\n",
            "('blob main', 0.0016126221101277751)\n",
            "('http github', 0.0017171318530604615)\n",
            "('href http', 0.0017758204515287634)\n",
            "('assignment blob', 0.001887642660108698)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yake\n",
        "\n",
        "\n",
        "def get_keywords_yake(idx, docs):\n",
        "    y = yake.KeywordExtractor(lan='en',          # language\n",
        "                             n = 10,              # n-gram size\n",
        "                             dedupLim = 0.95,     # deduplicationthresold\n",
        "                             dedupFunc = 'seqm', #  deduplication algorithm\n",
        "                             windowsSize = 1,\n",
        "                             top = 10,           # number of keys\n",
        "                             features=None)           \n",
        "    text = docs\n",
        "    keywords = y.extract_keywords(text)\n",
        "    return keywords\n",
        "\n",
        "def print_results(idx,keywords, df):\n",
        "    # now print the results\n",
        "    print(\"\\n===Keywords===\")\n",
        "    for k in keywords:\n",
        "        print(k)\n",
        "\n",
        "idx=11\n",
        "keywords = get_keywords_yake(idx, n2df[idx])\n",
        "print(n2df[idx])\n",
        "print_results(idx, keywords, n2df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d99vokIiMe7C",
        "outputId": "10a747f3-c219-4438-ff63-eac45aa1cc85"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "team getting error quot module named apos spacy token span_group apos quot even write import spacy got relevant information stack overflow possible kindly help sushant inviting scheduled zoom meeting topic sushant apos personal meeting room join zoom meeting href http web zoom pwd qle nmf auhhovbudetqr fubm pdz http web zoom pwd qle nmf auhhovbudetqr fubm pdz meeting passcode irye min wil share zooom link yes sure doesnt screen sharing button getting screen sharing icon yes talking talk yes case aware fine connect someone else morning time often even activated environment need manually select ctrl shift thats apos stuck team small issue apos unable fetch correct python interpreter code apos ubuntu connect min quick everything worked shown class team getting small error message stating record file getting generated per last weekend sunny apos class feb apos full stack batch connect someone min updating link help someone ineuron support team type smile href http doc google com spreadsheet duixvstvmaylom opwl vja nmia rpyuo edit gid http doc google com spreadsheet duixvstvmaylom opwl vja nmia rpyuo edit gid thanks ton thank link sheet detail generally updated href http doc google com spreadsheet duixvstvmaylom opwl vja nmia rpyuo edit gid http doc google com spreadsheet duixvstvmaylom opwl vja nmia rpyuo edit gid apos unable find link dashboard excel file new link get updated whole week class team kindly check extra class sunny full stack batch feb apos batch deep learning thank able recollect name tool name team kindly ping tool create flowchart diagram process flow getting error message loaded_model mlflow pyfunc load_model logged_model unboundlocalerror local variable apos logged_model apos referenced assignment team problem project working mlflow connect team document configure cloudera virtual box valueerror traceback recent call last appdata local temp ipykernel_ x_test reshape x_test shape model predict x_test valueerror cannot reshape array size shape warning connectionpool retrying retry total connect read redirect status connection broken apos newconnectionerror apos failed establish new connection winerror requested address valid context apos apos mlflow experiment get name experiment_name classification team working mlflow project error message case team help important interview question power day krish naik apos video per link mlops end end implementation deployment machine learning dvc path correctly updated connect min href http www youtube com watch ioabe dxb amp list plzotaelrmxvok prcocag xtxxgmalpie amp index http www youtube com watch ioabe dxb amp list plzotaelrmxvok prcocag xtxxgmalpie amp index shown github repo already updated train_and_evaluate params yaml dvc yaml file team apos unable get train evaluate level shown sunny apos class connect min dvc solution shown krish naik video team kindly update github repo last week aiops class sunday resource href http github com avnish census aiops http github com avnish census aiops yes see let check team getting error message per classification code kindly guide resolve team want configure system visual studio code able connect gpu already installed cuda cudnn system think need add path well environment variable kindly let know connect min href http tableau com article howto converting published extract live connection http tableau com article howto converting published extract live connection hello link working href http www affiliate ineuron http www affiliate ineuron version pickle mentioned requirement txt python copy usr app expose workdir usr app run pip install requirement txt cmd python app able getting error message team issue dockering project sure thank avnish checked video krish naik able find git action discussion time kindly share link exact video github action still try look video keep searching already tried referring stack overflow nothing seems working team working last project sunny aiops class mlflow_demo program giving error message per screenshot kindly help thank team kindly help understand get cluster mean clustering algorithums run ahead send cluster algorithums team kindly confirm extra ops class today team apos currently working flow project able save dataframe need another python file read dataframe process kindly help share link aiops doubt clearing session aiops team kindly confirm doubt clearing session today received mail regarding inception paper team feb dlcvnlp aug batch ipynb file discussed link added excel dashboard kindly share link issue got link yesterday someone support team said rescheduled today nope team apos unable get link dlcvnlp extra class today dashboard kindly help link dashboard team apos unable get link dlcvnlp batch extra class kindly share link team kindly share resource ipynb alexnet added dcvnlp batch added resource video link team resource ipynb alexnet added dcvnlp batch kindly share team issue dvc implementation connect min get link share build done push done done issue command failing team apos unable push created hub pull tisdes giving error thank run well used command quot docker build dogcat quot team trying create docker getting error message issue finding problem find explanation boosting algo found team able see screen team doubt dvc implementation connect min team getting error implementing dvc project connect min forgot ask paul mail dlcvnlp class kindly help team issue got cancellation mail team ops class started yet yes already added multiple city entity weather intent wind speed data reflecting correctly must small correction needed ask weather specific city response apos getting city name data coming correctly connect min team small issue google diagflow chatbot cifar bydefault dataset present tensorflow team need help working cifar dataset apos unable see class image present href http dialogflow cloud google com http dialogflow cloud google com quot sudh quot def test type list print type int append return print test team need help increasing accuracy early scheduler weight decay team mentorship timing available currently afternoon team kindly help dpr format needed prepare per sudhanshu class full stack interview preparation working dvc project implementation need help code correction kindly help team hello kindly help issue team revising old lecture aiops small doubt message connection refused mobaxterm tool aug lecture team dec session still uploaded dlcvnlp batch kindly help get done asap team kindly help upload yesterday ops session dashboard thank hello showing apos wanted check tried filter subtopics team unable see aiops course dashboard want purchase kindly help team would find live class link dashboard still keep href mailto sushant sur gmail com sushant sur gmail com see frankly calling checking apos help much coz take probably apos within week max actually though apply later since still many thing learn live class going thank team applying neuron lifetime free applied jan got thanks team kindly help see attachment full stack course apos able locate new dashboard kindly help get attachment uploaded till date unable see attachment new dashboard team anyone team apos unable fetch attachment full stack course new dashboard kindly help googled google dataset column column apos confused import numpy import panda import scipy stats stats import matplotlib pyplot plt import sklearn sklearn datasets import load_boston boston load_boston bos dataframe boston data initial code given team working boston data set assignment linear regression apos sure price column column thank working well team browsing website see problem wanted keep posted update team kindly confirm class weekend nan value getting replaced team want help line code trying replace nan value applying filter another column titanic dataset even write line code set dataset per cabin size apos fine apos loop apos complicated directly replacing mean overall dataset apos correct approach need help code cabin size dataset want replace age help would great category data filtered cabin size null value age column need replaced mean hope apos clear team need another small help coding want replace null value age column per mean category selected cabin size got see x_train x_test need apos error thank type smile wrote code x_train y_train x_test y_test train_test_split test_size random_state value row column row column valueerror traceback recent call last sklearn ensemble import randomforestregressor randomforestregressor n_estimators random_state fit x_train y_train anaconda lib site package sklearn ensemble _forest fit self sample_weight quot sparse multilabel indicator supported quot self _validate_data multi_output true accept_sparse quot csc quot dtype dtype sample_weight none anaconda lib site package sklearn base _validate_data self reset validate_separately check_params check_array check_y_params else check_x_y check_params anaconda lib site package sklearn utils validation inner_f args kwargs extra_args len args len all_args extra_args return args kwargs extra_args anaconda lib site package sklearn utils validation check_x_y accept_sparse accept_large_sparse dtype order copy force_all_finite ensure_ allow_nd multi_output ensure_min_samples ensure_min_features y_numeric estimator astype float check_consistent_length return anaconda lib site package sklearn utils validation check_consistent_length array uniques unique length len uniques raise valueerror quot found input variable inconsistent number quot quot sample quot int length valueerror found input variable inconsistent number sample please let know screen share min get small help team apos working random forest regressor problem run regressor fit getting error message quot found input variable inconsistent number sample quot team small issue working ops video shown sunny krish naik channel kindly help possible kindly share link dsa study group started team devops session ritesh started today hello team november lecture dlcvnlo yet uploaded kindly help get done earliest possible trying open jupyter notebook even try close message coming team getting error message kindly help resolve class today team kindly confirm extra class dlcvnlp batch actually yesterday sunny told wont needed see new link updated dashboard href http git lf github com http git lf github com asking svm classifier model taking huge time train along grid search yes team want know way create checkpoint machine learning process apos aware deep learning thank ritesh team devops session started titanic_mod titanic_mod apos cabin apos amp titanic_mod apos cabin apos amp titanic_mod apos cabin apos amp titanic_mod apos cabin apos amp titanic_mod apos cabin apos amp titanic_mod apos cabin apos apos age apos mean inplace true kindly help code team titanic dataset want replace age column nan value respect cabin column per split hello apos logistic regression problem team kindly help error thank think ritesh busy working project team devops session today kindly confirm exrj team viewer able hear able hear team need help deploying pypi library apos getting error code extra class last day dlcvnlp batch ist kindly let know would session today apos see new live meeting updated dashboard team let check well href http codeshare vvv http codeshare vvv code exactly taught class functionality vif getting error building pypi library functionality completed first function handling null value standardizing value numpy data frame team need help working pypi project vif code giving error thank yes internship portal able find recommendation system project wanted check thank please let know missed check internship project needed team recommendation system project machine learning able find nay thank team see project computer vision resource project like helmet detection etc explanatory video available code thanks ton type _beamingfacewithsmilingeyes beamingfacewithsmilingeyes thank dlcvnlp kindly check confirm python code supporting updated team unable see document google diagflow chatbot explained last week team random forest assignment dataset link mentioned word document kindly help thank kindly let know case cancelled devops git ops session started today hello team thanks team full stack batch starting late today team unable see yesterday class video full stack batch thank deep learning class team small problem ann implementation log directory getting created team devops session day started ineuron intelligence channel dont find link thanks help team issue pypi library creation getting error message sure thank team problem yolo basic implementation give assertion error stage load save file running giving error message even though matched code github repo per taught class team able solve error dlcvnlp batch last weekend lecture tensorflow dvc thank confirmation team class happening weekend aws full stack batch super thanks kfuu teamviewer get error validated config yaml file training file completely dlcvnp class ann implementation team saturday apos session apos getting error per src folder common file correct kfuu conda command team getting error message working pycharm team link dsa community session starting thank mkdb team code dvc repro giving error line item updated dvc yaml file thats working fine thanks lot help hmq team issue working dvc implementation lecture last weekend stuck create artifact file somehow giving error wanted understand concept behind saw question video answer able find googling team kindly help understand hard soft classifier svm someone picking issue dpr report much similar initial format give per project requirement checked someone else whose project approved href mailto contact ineuron contact ineuron last received mail href mailto contact ineuron contact ineuron kindly help someone team would reviewing internship project send mail response team thank much sure sure thanks href mailto sushant sur gmail com sushant sur gmail com hope understand issue technical glitch still showing cart query bought course showing course right thats showing see recorded video bought course data structure received final confirmation mail apos account currently issue course purchased online team class assignment yes output form number atmospheric pressure example linear regression worked class assignment fast apos getting small error output kindly look share github link issue app file team href mailto sushant sur gmail com sushant sur gmail com mail team kindly help add mail group mail box apos getting mail related job alert thank meeeting started hello still apos see link updated sure thank full stack program apos see link updated dashboard doubt clearing session start today kindly help team thank question pickle file creation could reason pickle file size huge amount coding involved team thank normally distributed want bring nornal distribution column either value kindly help problem column data frame apos tool wear min apos categorical nature want convert bernoulli distribution convert normal distribution apos able get code kindly help team thank apos see class recording uploaded aws master class sat kindly help team need use code config completer use_jedi false new jupyter notebook get relevant suggestion writing code team connect vikash someone else possible get help trying work earlier video checking casandra installation able detect folder location furthur type command apos apos apos able see output stating file inside folder team stuck authentication part issue push document git repo getting error message kindly help connect technical team tried restarting system still apos work team sure issue internship dashboard looking aviation project machine learning colleague able see apos unable see reason team apos int apos object subscriptable tried add return statement getting error len new range apos apos return new append new need whole list return value cow repeated twice returned list value cow added end def dupl lst newl len lst range range lst lst newl append lst apos apos else new append lst return newl lst apos cow apos apos buffalo apos apos goat apos apos sheep apos apos cow apos print dupl lst question add end string repeated action repeated apos facing small error program team sorry issue join link mentioned mail apos see new meeting link updated aws doubt clearing session let know missing info team great thanks today apos class sudhanshu asked write answer question uploaded interview question link see answer already mentioned question question need attempt answer knowledge team fyi database access change password without uninstalling changed password get connected atlas got error issue used setting password giving error document apos apos needed apos fine connect local mongo database wanted understand issue connecting atlas issue check someone doubt clearing session let know easier share screen error apos getting kindly help invaliduri username password must escaped according rfc use urllib parse quote_plus code username user password lenovo import pymongo client href mailto pymongo mongoclient quot mongodb srv user pymongo mongoclient quot mongodb srv user myfirstdatabase retrywrites true amp majority quot client test revising previous video small error difficulty connecting mongo atlas team kindly help installed visual studio installer check per button still give error trying install sql per previous class facing issue let know understanding wrong would right time take help ineuron apply job apos asking question past video advised python session completion statistic forward resume right fill internship form fill went previous video previous class need suggestion joined full stack course july revising previous video completing assignment well team got screenshot understand use raw_pre raw_post _init_ method use constructor later used raw_pre raw_post _str_ required print statement reason well team question screenshot let know god time ask sure thank let know helpful resource question asked general interview like find size shark sea would idea recorded video provide example like tried check video krish naik found yet team work otu thanks lot valueerror traceback recent call last max max remove max append max print valueerror list remove list sort print int input apos many number need list apos max range len max max remove max append max print program find largest number list ask small help correct program error coming team python basic assignment write string newlines apos want use character understand apos use string cow eating grass need output showing word different line item team kindly hep understand problem statement assignment want know output need shown work problem creating list exact key value pair needed apos need mention even key value get replaced let know apos correct answer spam color black basic python assignment shortcut following code apos color apos spam spam apos color apos apos black apos team got thanks ton yes press tab adviced sudhanshu class team apos able get option class jupyter notebook idea issue installation process yeah got thanks python basic assignment variable quot contain quot list value necessarily list instead contain apos unable understand question assignment thanks ton class beacon def spam print quot hello quot beacon spam program would would call function beacon spam correct didnt understand meaning question bacon feature spam module would call importing spam yes got solution function within class function named bacon inside module named spam would call importing spam small doubt assignment question team thank correct need communicate registered mail kindly help access ineuron mailbox didnt get answer yesterday somehow joined full stack course day team update see mail mentioned link mail box yes went see course registered enrolled apos see mail box call min checked check sindhu asked contact support team enrolled full stack course yesterday july apos know get link use ineuron mailbox kindly guide apos sure access mail box link use apology apos new ineuron kindly help mailbox access registered mail href mailto sushant sur gmail com sushant sur gmail com team joined full stack data science course yesterday need help mailbox access kindly help type wave\n",
            "\n",
            "===Keywords===\n",
            "('fine thanks lot help hmq', -0.5714103418795576)\n",
            "('vikash someone else possible get help trying work', -0.07104252758472397)\n",
            "('earliest possible trying open', -0.06683898824439605)\n",
            "('searching already tried referring', -0.060607935487285595)\n",
            "('constructor later used raw', -0.05230006039278884)\n",
            "('notebook even try close', -0.0468505794759677)\n",
            "('wrong would right time', -0.04570411478113724)\n",
            "('overflow nothing seems working', -0.04429270030972624)\n",
            "('time ask sure thank let know helpful', -0.04055022682211995)\n",
            "('experiment get name experiment', -0.03802327566568837)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customer service"
      ],
      "metadata": {
        "id": "PDZABYqToJpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count =0\n",
        "stri = \"\"\n",
        "data = []\n",
        "listn = []\n",
        "\n",
        "for i in df['conversations'][0:16000]:\n",
        "  listn= []\n",
        "  for k in i['MessageList']:\n",
        "    if(k['displayName'] is None and k['messagetype']== 'RichText'):\n",
        "        stri = stri + \" \" + k['content']\n",
        "    else:\n",
        "      if(stri is not \"\"):\n",
        "        listn.append(stri)\n",
        "        stri = \"\"\n",
        "  \n",
        "  data.append(listn)\n",
        "  count = count +1"
      ],
      "metadata": {
        "id": "p4fP_gAmOhDp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.asarray(data)\n",
        "data.reshape(-1)\n",
        "out_df = pd.DataFrame(data, columns=['Content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDJarThwoRvb",
        "outputId": "8350713e-2d14-49af-8314-2ae5f78ca5f3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for i in range(len(out_df['Content'])):\n",
        "  mx = -1\n",
        "  ans = \"\"\n",
        "  for k in out_df['Content'][i]:\n",
        "    if len(k) > mx:\n",
        "      ans = k\n",
        "      mx = len(k)\n",
        "  data.append([i,ans])\n"
      ],
      "metadata": {
        "id": "nORjWGduoU_d"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out2_df = pd.DataFrame(data, columns=['Count', 'Content'])\n",
        "out2_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HmssWzqgoWpK",
        "outputId": "b6ab03f7-3686-4e3b-d0e7-aabaa715006d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Count                                            Content\n",
              "0          0   Not possible this is account realted problem ...\n",
              "1          1   <quote author=\"live:.cid.78533d4cb35406cc\" au...\n",
              "2          2   first if it is possible you can download  Ple...\n",
              "3          3   What you are displaying is the recently playe...\n",
              "4          4   <quote author=\"live:mayanktamboli\" authorname...\n",
              "...      ...                                                ...\n",
              "15995  15995   for both the course  sir you can use this one...\n",
              "15996  15996   hope this will clarify your doubt  <a href=\"h...\n",
              "15997  15997   <a href=\"https://canvas.instructure.com/enrol...\n",
              "15998  15998   <quote author=\"live:.cid.4933a22bf564744\" aut...\n",
              "15999  15999   then we will be able to do it  in calss  let ...\n",
              "\n",
              "[16000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea89b7a5-a2dc-4426-a5b1-a0b3ab06633b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Not possible this is account realted problem ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;quote author=\"live:.cid.78533d4cb35406cc\" au...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>first if it is possible you can download  Ple...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>What you are displaying is the recently playe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>&lt;quote author=\"live:mayanktamboli\" authorname...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15995</th>\n",
              "      <td>15995</td>\n",
              "      <td>for both the course  sir you can use this one...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15996</th>\n",
              "      <td>15996</td>\n",
              "      <td>hope this will clarify your doubt  &lt;a href=\"h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>15997</td>\n",
              "      <td>&lt;a href=\"https://canvas.instructure.com/enrol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15998</th>\n",
              "      <td>15998</td>\n",
              "      <td>&lt;quote author=\"live:.cid.4933a22bf564744\" aut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15999</th>\n",
              "      <td>15999</td>\n",
              "      <td>then we will be able to do it  in calss  let ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea89b7a5-a2dc-4426-a5b1-a0b3ab06633b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea89b7a5-a2dc-4426-a5b1-a0b3ab06633b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea89b7a5-a2dc-4426-a5b1-a0b3ab06633b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out2_df['Content'][9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mv1BulsWM-zk",
        "outputId": "0044e2d6-14a5-4a82-d2d7-ade239c9c618"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' that will be enough just upload the link of that repo it is just beacuse of file size don&apos;t worry about that'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}